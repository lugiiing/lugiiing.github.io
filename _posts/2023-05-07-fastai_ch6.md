---
layout: post
title: "fastai_ch6"
---




## Other Computer Vision Problems _Multi-Label Classification

- There may be more than one kind of object, or there may be no objects at all in the classes that you are looking for.
- zero shot?

### Constructing a DataBlock
- Datasets:: An object that contains a training Dataset and a validation Dataset
- DataLoaders:: An object that contains a training DataLoader and a validation DataLoader
- DataFrame to DataLoaders object: data block Api


```python
! pip install -Uqq fastbook
import fastbook
fastbook.setup_book()
```


```python
from fastbook import *
```


```python
from fastai.vision.all import *
path = untar_data(URLs.PASCAL_2007)
```


```python
df = pd.read_csv(path/'train.csv')
df.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>fname</th>
      <th>labels</th>
      <th>is_valid</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>000005.jpg</td>
      <td>chair</td>
      <td>True</td>
    </tr>
    <tr>
      <th>1</th>
      <td>000007.jpg</td>
      <td>car</td>
      <td>True</td>
    </tr>
    <tr>
      <th>2</th>
      <td>000009.jpg</td>
      <td>horse person</td>
      <td>True</td>
    </tr>
    <tr>
      <th>3</th>
      <td>000012.jpg</td>
      <td>car</td>
      <td>False</td>
    </tr>
    <tr>
      <th>4</th>
      <td>000016.jpg</td>
      <td>bicycle</td>
      <td>True</td>
    </tr>
  </tbody>
</table>
</div>




```python
dblock = DataBlock()

dsets = dblock.datasets(df)

len(dsets.train),len(dsets.valid)
```




    (4009, 1002)




```python
x,y = dsets.train[0]
x,y
```




    (fname       008663.jpg
     labels      car person
     is_valid         False
     Name: 4346, dtype: object,
     fname       008663.jpg
     labels      car person
     is_valid         False
     Name: 4346, dtype: object)




```python
# prints same thing twice ; need to separate into x and y -> get_x, get_y
x['fname']

dblock = DataBlock(get_x = lambda r: r['fname'], get_y = lambda r: r['labels'])
dsets = dblock.datasets(df)
dsets.train[0]
```




    ('005620.jpg', 'aeroplane')




```python
# shorter way for serialization

def get_x(r): return r['fname']
def get_y(r): return r['labels']
dblock = DataBlock(get_x = get_x, get_y = get_y)
dsets = dblock.datasets(df)
dsets.train[0]
```




    ('002549.jpg', 'tvmonitor')




```python
# x는 path로 저장해서 열 수 있도록
# y는 스페이스로 구분된 리스트 형태로 (!왜 스페이스로 했을까? , 아니고?)

def get_x(r): return path/'train'/r['fname']
def get_y(r): return r['labels'].split(' ')
dblock = DataBlock(get_x = get_x, get_y = get_y)
dsets = dblock.datasets(df)
dsets.train[0]
```




    (Path('C:/Users/변규리/.fastai/data/pascal_2007/train/002844.jpg'), ['train'])



- 실제로 열기 위해서는 변환 필요 -> block typed transforms
- image block: 사용 가능 (path 만들었으니까)
- categoryblock: 사용 불가, y값이 하나의 정수로 반환됨, 한 이미지에 여러 라벨(y) 붙이기에는 부적합
- multicategoryblock: list of string 받을 수 있음, y값이 원핫인코딩'처럼' 반환됨(여러 개를 1로 설정할 수 있으니 multi-hot..)


```python
dblock = DataBlock(blocks=(ImageBlock, MultiCategoryBlock),
                   get_x = get_x, get_y = get_y)
dsets = dblock.datasets(df)
dsets.train[0]
```




    (PILImage mode=RGB size=500x375,
     TensorMultiCategory([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]))



- x값은 'PILImage mode=RGB size=500x375' 이렇게 반환
- y값은 카테고리들 리스트 0으로 반환하고 그 중에서 해당하는 것에 1으로 반환됨


```python
idxs = torch.where(dsets.train[0][1]==1.)
idxs
```




    (TensorMultiCategory([11]),)




```python
idxs = torch.where(dsets.train[0][1]==1.)[0]
# dsets.train[0][1]==1. -> dsets.train의 첫번째 데이터의 y값 중 1인 것
# torch.where()[0] -> 괄호 안의 조건에 맞는 것 찾은 다음 그 중에서 첫번째
# (=torch.where()은 튜플 반환인데 그 중 왼쪽에는 y 리스트 중 조건에 맞는 것이 몇번째에 있는지 적혀있음)

dsets.train.vocab[idxs]
```




    (#1) ['dog']



- ['is_valid']: means DataBlock has been using a random split by default
- 이용해서 다시 데이터셋 만들어주기


```python
def splitter(df):
    train = df.index[~df['is_valid']].tolist()
    valid = df.index[df['is_valid']].tolist()
    return train,valid

dblock = DataBlock(blocks=(ImageBlock, MultiCategoryBlock),
                   splitter=splitter,
                   get_x=get_x, 
                   get_y=get_y)

dsets = dblock.datasets(df)
dsets.train[0]
```




    (PILImage mode=RGB size=500x333,
     TensorMultiCategory([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]))



- 데이터 사이즈 모두 같게


```python
dblock = DataBlock(blocks=(ImageBlock, MultiCategoryBlock),
                   splitter=splitter,
                   get_x=get_x, 
                   get_y=get_y,
                   item_tfms = RandomResizedCrop(128, min_scale=0.35))
dls = dblock.dataloaders(df)
```

- check


```python
dls.show_batch(nrows=1, ncols=3)
```


    
![png](/../../images/fastai_ch6/output_21_0.png)
    


### before start 'learn': Binary Cross-Entropy

- learner's 4 main things: the model, a DataLoaders, an Optimizer, the loss fuction
- model -> resnet
- DataLoader -> just made
- Optimizer -> SDG
- loss finc -> from now on..


```python
# make learner and see how the loss function works
learn = vision_learner(dls, resnet18)
```

    C:\Users\변규리\AppData\Local\Programs\Python\Python311\Lib\site-packages\torchvision\models\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
      warnings.warn(
    C:\Users\변규리\AppData\Local\Programs\Python\Python311\Lib\site-packages\torchvision\models\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
      warnings.warn(msg)
    

- model in a Learner: generally an object of a class inheriting from "nn.Module"
- mini batch 하나 넣어서 어떻게 작동하는지 알아보기


```python
x,y = to_cpu(dls.train.one_batch())
activs = learn.model(x)
activs.shape
```




    torch.Size([64, 20])



- ! 우리가 batch size 64로 정해준 적이 있었나,,,?
- 20은 카테고리 개수


```python
activs[0]
# 예측한 것 하나 샘플로
```




    TensorImage([ 0.5674, -1.2013,  4.5409, -1.5284, -0.6600,  0.0999, -2.4757, -0.8773, -0.2934, -1.4746, -0.1738,  2.1763, -3.4473, -1.1407,  0.1783, -1.6922, -2.3396,  0.7602, -1.4213, -0.4334],
                grad_fn=<AliasBackward0>)



- scaling it between 0 and 1 by sigmoid (softmax 쓰지 않고 개별 카테고리에 대해 시그모이드 각각 사용)
- and calc loss by adding -log on it
    - 타겟이 원핫 인코딩 되어있어서 바로 nll_loss, softmax(활성함수), cross_entropy(= -ln(sftmx), loss) 쓸 수 없음
    - 그리고 multi index 사용할 것이라서 act func 거친 합이 1이 되는 것 bad


```python
def binary_cross_entropy(inputs, targets):
    inputs = inputs.sigmoid()
    return -torch.where(targets==1, inputs, 1-inputs).log().mean()
# 로그에 들어갈 값은 클수록 정확한 것
# 타겟이 1이어야 하는 것은 시그모이드 반환값이 클수록 정확한 것
# -> 그대로 인풋 사용
# 타겟이 0이어야 하는 것은 시그모이드 반환값이 작을수록 정확한 것
# -> 인풋 그대로 사용하면 '작을수록 정확하다' <-> '로그에 들어가는 것은 클수록 정확' 반대
# -> 1-인풋 사용
### 태블릿에 그림 ###
```

- binary_cross_entropy: 변경 없이 배치와 단일 아이템 모두에 잘 적용됨
- (do not include the initial sigmoid) F.binary_cross_entropy = nn.BCELoss
- (with sigmoid) F.binary_cross_entropy_with_logits = nn.BCEWithLogitsLoss

--------------
c.f. multicat 아닌 경우의 같은 예시들
- (do not include the initial softmax) F.nll_loss = nn.NLLLoss
- (with softmax) F.cross_entropy = nn.CrossEntropyLoss


```python
TensorImage.register_func(torch.nn.functional.smooth_l1_loss, TensorImage, TensorBBox)
TensorMultiCategory.register_func(TensorMultiCategory.mul, TensorMultiCategory, TensorImage)
TensorImage.register_func(torch.nn.functional.binary_cross_entropy_with_logits, TensorImage, TensorMultiCategory)
```


```python
l_func = nn.BCEWithLogitsLoss()
loss1 = l_func(activs, y)
loss1
```




    TensorImage(1.0367, grad_fn=<AliasBackward0>)



accuracy는 멀티라벨에서는 metric으로 사용 불가

    def accuracy(inp, targ, axis=-1):

        #Compute accuracy with `targ` when `pred` is bs * n_classes
    
        pred = inp.argmax(dim=axis)
    
        return (pred == targ).float().mean()
    
-> 하나의 max input만 사용하다 보니 멀티라벨에 부적합

- sigmoid 후 무엇이 0이고 1인지 threshold pick 하여 알아내야 함 (threshold 기준점 이상은 1이고 이하는 0)


```python
def accuracy_multi(inp, targ, thresh=0.5, sigmoid=True):
    # Compute accuracy when `inp` and `targ` are the same size.
    if sigmoid: inp = inp.sigmoid()
    return ((inp>thresh)==targ.bool()).float().mean()

# thresh 자리에 아무것도 안 쓰면 0.5로 계산하지만
# 무언가를 넣으면 그것으로 계산함
# = partial
```

### learn


```python
learn = vision_learner(dls, resnet50, metrics=partial(accuracy_multi, thresh=0.2))
learn.fine_tune(2, base_lr=3e-3, freeze_epochs=1)
```

    C:\Users\변규리\AppData\Local\Programs\Python\Python311\Lib\site-packages\torchvision\models\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.
      warnings.warn(msg)
    



<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>




<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy_multi</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.857111</td>
      <td>0.571763</td>
      <td>0.339542</td>
      <td>17:55</td>
    </tr>
  </tbody>
</table>




<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>




<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy_multi</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.536245</td>
      <td>0.316719</td>
      <td>0.562111</td>
      <td>27:42</td>
    </tr>
    <tr>
      <td>1</td>
      <td>0.380012</td>
      <td>0.222559</td>
      <td>0.771614</td>
      <td>22:38</td>
    </tr>
  </tbody>
</table>


threshold 선정 중요 (너무 낮으면 죄다 맞다고 해버림, 높으면 very confident한것만 맞다고 함)

-> validate()로 valloss와 metric 보면서 metric을 바꿔가면서 적용해보기


```python
learn.metrics = partial(accuracy_multi, thresh=0.1)
learn.validate()

# !여기서 출력되어 나오는 리스트가 의미하는 것이 뭘까?
# valloss, acc 라고 합니다!
# valloss는 모델 트레이닝 마지막 이터레이션과 계속 같다
# 근데 책에 acc가 이상하게 나와있어서 엄청 헷갈렸음.. 
# 위랑 아래 thresh가 엄청 다른데 acc는 거의 같았단말이다...
```



<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>










    (#2) [0.22255949676036835,0.3520716428756714]




```python
learn.metrics = partial(accuracy_multi, thresh=0.99)
learn.validate()
```



<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>










    (#2) [0.22255949676036835,0.9416731595993042]




```python
preds,targs = learn.get_preds()

preds,targs

# 각각의 카테고리에 대한 예측값과 실제 타깃값을 반환
# 그럼 learn.validation에서 반환하는 쟤는 뭐지,..
```



<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>










    (tensor([[0.0918, 0.1733, 0.0893,  ..., 0.6791, 0.0658, 0.3026],
             [0.1645, 0.1489, 0.1155,  ..., 0.2120, 0.3138, 0.1032],
             [0.0803, 0.7652, 0.0434,  ..., 0.0808, 0.0418, 0.0944],
             ...,
             [0.2223, 0.1211, 0.0986,  ..., 0.1487, 0.1476, 0.1698],
             [0.1798, 0.1606, 0.1336,  ..., 0.0826, 0.1381, 0.0786],
             [0.0675, 0.9536, 0.1739,  ..., 0.1600, 0.1131, 0.1374]]),
     tensor([[0., 0., 0.,  ..., 0., 0., 0.],
             [0., 0., 0.,  ..., 0., 0., 0.],
             [0., 0., 0.,  ..., 0., 0., 0.],
             ...,
             [0., 0., 0.,  ..., 0., 0., 0.],
             [0., 0., 0.,  ..., 0., 0., 0.],
             [0., 1., 0.,  ..., 0., 0., 0.]]))




```python
# learn으로 나온 preds를 acc에 넣어서 알아보기

preds,targs = learn.get_preds()

xs = torch.linspace(0.05,0.95,29)
# 0.05 부터 0.95까지 29개로 나눠서 어떤 thresh가 가장 적합한지 알아보기

accs = [accuracy_multi(preds, targs, thresh=i, sigmoid=False) for i in xs]
plt.plot(xs,accs);
# get_preds()에서 act func(여기서는 sig)자동 적용되니 accuracy_multi에서는 빼주기
```



<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>








    
![png](/../../images/fastai_ch6/output_41_2.png)
    


- 그래프가 smooth해서 overfit 걱정은 안해도 됨
- 적당한 지점에서 thresh 구하기
- 자동 업데이트 시키는 방법도 분명 있을텐데,,

## Other Computer Vision Problems _Regression (image)

- 너무 세분화해서 생각하기 보다는 큰 범주로 생각할 필요가 있음. 조합의 가능성은 굉장히 많다!!
- image regression은 inde var이 image, de var이 float(s)
- 여기서는 사람의 얼굴 중앙(row, column of face center)을 찾아내는 모델을 만들 것

### data prepare


```python
path = untar_data(URLs.BIWI_HEAD_POSE)
```



<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>





<div>
  <progress value='452321280' class='' max='452316199' style='width:300px; height:20px; vertical-align: middle;'></progress>
  100.00% [452321280/452316199 01:05&lt;00:00]
</div>




```python
Path.BASE_PATH = path
```


```python
path.ls().sorted()
```




    (#50) [Path('01'),Path('01.obj'),Path('02'),Path('02.obj'),Path('03'),Path('03.obj'),Path('04'),Path('04.obj'),Path('05'),Path('05.obj')...]



- 24 디렉토리: 각각 다른 사람의 사진들
- obj: 각각에 대한 obj 파일


```python
(path/'01').ls().sorted()
```




    (#1000) [Path('01/depth.cal'),Path('01/frame_00003_pose.txt'),Path('01/frame_00003_rgb.jpg'),Path('01/frame_00004_pose.txt'),Path('01/frame_00004_rgb.jpg'),Path('01/frame_00005_pose.txt'),Path('01/frame_00005_rgb.jpg'),Path('01/frame_00006_pose.txt'),Path('01/frame_00006_rgb.jpg'),Path('01/frame_00007_pose.txt')...]



- 여러 프레임들의 jpg 파일과 그것에 해당하는 pose txt 파일


```python
img_files = get_image_files(path)
# !하나 밑의 디렉토리까지 자동으로 접근해주나? (path 밑에 01,02,,, 들어가야 이미지 나오는데..?)
def img2pose(x): return Path(f'{str(x)[:-7]}pose.txt')
img2pose(img_files[0])
# 밑에 출력된 걸 보면 '13/frame...'이라서 밑에까지 자동으로 접근한다음 출력하는 것 같다
# img_files 즉 get_image_files(path)로 반환되는 글자는 'frame_어쩌구_rgb.jpg'였음 (get_image_files가 이미지 파일명을 긁어오나보다)
# 그래서 [:-7]을 통해서 'rgb.jpg'를 없애주고 뒤에 pose.txt 붙임
```




    Path('01/frame_00003_pose.txt')




```python
im = PILImage.create(img_files[0])
im.shape

# PILImage 위에부터 많이 보이던데.. Pillow(이미지 처리 클래스)였음:) 
```




    (480, 640)




```python
im.to_thumb(160)
```




    
![png](/../../images/fastai_ch6/output_53_0.png)
    




```python
cal = np.genfromtxt(path/'01'/'rgb.cal', skip_footer=6)
def get_ctr(f):
    ctr = np.genfromtxt(img2pose(f), skip_header=3)
    c1 = ctr[0] * cal[0][0]/ctr[2] + cal[0][2]
    c2 = ctr[1] * cal[1][1]/ctr[2] + cal[1][2]
    return tensor([c1,c2])

# 이 함수를 DataBlock의 get_y로 사용 가능 (각 아이템에 대해 y 구할 수 있음)


# ! 이게 왜 센터 위치 구하는 함수?
# np.genfromtxt: 텍스트 파일을 열어준다, 컬럼별로 구분해준다
# (img2pose(f), skip_header=3) =  윗윗윗셀 출력결과에서 앞 3개 뺌 = 'frame_어쩌구.txt'
# ctr = 'frame_어쩌구.txt'를 np.genfromtxt로 열어본 결과
# 즉, 해당 그림에 매치되어있던 텍스트 파일을 컬럼별로 구분해서 열어본 결과
# 열린 텍스트 파일에 모종의 연산(cal에 저장되어있는 기본 행렬 이용)을 통해서 c1, c2 구해냄
# 이렇게 해서 중심점 구했음!

# cal = np.genfromtxt(path/'01'/'rgb.cal', skip_footer=6)을 출력해보자
```


```python
cal
```




    array([[517.679,   0.   , 320.   ],
           [  0.   , 517.679, 240.5  ],
           [  0.   ,   0.   ,   1.   ]])




```python
get_ctr(img_files[0])

# 이게 센터
```




    tensor([350.4915, 262.9643])




```python
img_files[0]
```




    Path('01/frame_00003_rgb.jpg')



- valid는 랜덤으로 하면 XXX
- 아직 보지 못한 사람에 대해 맞춰야 하므로


```python
biwi = DataBlock(
    blocks=(ImageBlock, PointBlock),
    get_items=get_image_files,
    get_y=get_ctr,
    splitter=FuncSplitter(lambda o: o.parent.name=='13'),
    batch_tfms=aug_transforms(size=(240,320)), 
)

# pointblock 이 있어야 augment할 때 타겟값도 같이 변형
```


```python
# check

dls = biwi.dataloaders(path)
dls.show_batch(max_n=9, figsize=(8,6))
```


    
![png](/../../images/fastai_ch6/output_60_0.png)
    



```python
xb,yb = dls.one_batch()
xb.shape,yb.shape

# x는 한 배치에 64장, 3컬러채널, 가로 240, 세로 320
# y는 한 배치에 64개, ! 1*2는 좌표의 구조(x,y = 행 1개, 열 2개니까), 처음에는 순간 왜 1*1이 아닌지 의문이었음 (바보,,,)
```




    (torch.Size([64, 3, 240, 320]), torch.Size([64, 1, 2]))




```python
yb[0]
```




    TensorPoint([[0.2299, 0.0143]])



### Learn


```python
learn = vision_learner(dls, resnet18, y_range=(-1,1))
# y값 범위 결정
```


```python
# !y값 범위 왜 -1,1인지 아무리 찾아도 안나온다!

def sigmoid_range(x, lo, hi): return torch.sigmoid(x) * (hi-lo) + lo
plot_function(partial(sigmoid_range,lo=-1,hi=1), min=-4, max=4)
```


    
![png](/../../images/fastai_ch6/output_65_0.png)
    


- loss func는 정해주지 않아도 알아서 mse로 설정


```python
dls.loss_func
```




    FlattenedLoss of MSELoss()



- learnng rate 찾기


```python
learn.lr_find()

# 너무 오래걸려서 중간에 끔
```


```python
lr = 1e-2
learn.fine_tune(2, lr)
```



<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>




<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.046284</td>
      <td>0.004049</td>
      <td>2:00:36</td>
    </tr>
  </tbody>
</table>




<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>




<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.007038</td>
      <td>0.000444</td>
      <td>3:24:52</td>
    </tr>
    <tr>
      <td>1</td>
      <td>0.001901</td>
      <td>0.000072</td>
      <td>3:32:40</td>
    </tr>
  </tbody>
</table>


- 확인


```python
learn.show_results(ds_idx=1, nrows=3, figsize=(6,8))
```



<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>








    
![png](/../../images/fastai_ch6/output_72_2.png)
    


## conclusion

- 다 하나의 큰 틀로 생각하기
- 상황에 따라 loss func만 좀 잘 사용하기
    - nn.CrossEntropyLoss for single-label classification
    - nn.BCEWithLogitsLoss for multi-label classification
    - nn.MSELoss for regression
- 내 생각에는 마지막 act func도 꽤 신중하게 골라야 할듯
