---
layout: post
title: "fastai_ch7"
---



```python
#hide
! pip install -Uqq fastbook
import fastbook
fastbook.setup_book()
```


```python
from fastbook import *
```

## Training a State-of-the-Art Model

- learning from scratch , or using very different kind of pre-trained model

### Imagenette 데이터 이용
- large dataset: imagenet, mnist, cifar10
- but the smaller fataset didn't generalize effectivly to the large imagenet
- only people with super computer can make it? NOPE!
- 10개의 이미지 클래스만 뽑아서 수행, 전략효과성 테스트
- transfer learning 없이 모델 성능 올리기 


```python
# 베이스라인 모델

from fastai.vision.all import *
path = untar_data(URLs.IMAGENETTE)
```


```python
dblock = DataBlock(blocks=(ImageBlock(), CategoryBlock()), 
                   get_items=get_image_files, get_y=parent_label, 
                   item_tfms=Resize(460), 
                   batch_tfms=aug_transforms(size=224, min_scale=0.75)) 
dls = dblock.dataloaders(path, bs=32)
```


```python
model = xresnet50(n_out=dls.c) 
learn = Learner(dls, model, loss_func=CrossEntropyLossFlat(), metrics=accuracy) 
learn.fit_one_cycle(2, 3e-3)
```



<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>




<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>1.485646</td>
      <td>1.442383</td>
      <td>0.538835</td>
      <td>1:05:58</td>
    </tr>
    <tr>
      <td>1</td>
      <td>0.984283</td>
      <td>0.900131</td>
      <td>0.722928</td>
      <td>1:06:23</td>
    </tr>
  </tbody>
</table>


### Normalization

- 정규화하면 성능 개선의 효과 있음


```python
# 정규화 전 확인

x,y = dls.one_batch()
x.mean(dim=[0,2,3]),x.std(dim=[0,2,3])
```




    (TensorImage([0.4551, 0.4467, 0.4066]), TensorImage([0.2577, 0.2439, 0.2730]))




```python
# 정규화
def get_dls(bs, size):
    dblock = DataBlock(blocks=(ImageBlock, CategoryBlock),
                       get_items=get_image_files, get_y=parent_label, 
                       item_tfms=Resize(460),
                       batch_tfms=[*aug_transforms(size=size, min_scale=0.75), 
                                   Normalize.from_stats(*imagenet_stats)])
    return dblock.dataloaders(path, bs=bs)
```


```python
# 정규화 후 확인
dls = get_dls(64, 224)

# 정규화 후 확인
x,y = dls.one_batch()
x.mean(dim=[0,2,3]),x.std(dim=[0,2,3])

# 성능확인
model = xresnet50(n_out=dls.c) 
learn = Learner(dls, model, loss_func=CrossEntropyLossFlat(), metrics=accuracy) 
learn.fit_one_cycle(2, 3e-3)
```



<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>




<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>1.552039</td>
      <td>2.311168</td>
      <td>0.441374</td>
      <td>1:19:32</td>
    </tr>
    <tr>
      <td>1</td>
      <td>1.039746</td>
      <td>0.947530</td>
      <td>0.700896</td>
      <td>1:19:22</td>
    </tr>
  </tbody>
</table>


- 원래는 더 큰 효과 있다
- pretrained 사용할 때 원래 데이터(대규모)의 분포에 맞게 내 데이터 정규화해서 맞춰주면 성능 훨 좋음
- (그뿐만 아니라 다룰 피쳐가 여러개일때 피쳐 간의 최소 최댓값을 동일 하게 mm 맞춰주는 것도 좋음)

### Progressive Resizing

- 점점 큰 크기의 이미지로 트레이닝 시키기
- 픽셀 모두 같은 그기로 맞추기 전에 각 이미지를 더 작은사이즈로 트레이닝(빠른 속도) -> 그 다음 큰 이미지 트레이닝 시켜서(정확성) 성능 올리기
- CNN도 이미지 크기 제각각 (처음에는 edges, gradients, 나중에는 nose, sunsets) -> 이미지 크기가 중간에 바뀌는 것은 문제되지 않는다!
- 이미지 크기가 바뀌는 것을 모델에게 잘 알려주기 위해 resize 후 transfer learning하는 것 처럼 fine_tune 사용해서 기존과는 다른 데이터도 학습할 수 있도록 함
- another form of data augmentation -> 새로운 데이터에 대한 능력 더 좋음 (more general)


```python
# 먼저 작은 이미지

dls = get_dls(128, 128)
learn = Learner(dls, xresnet50(n_out=dls.c), loss_func=CrossEntropyLossFlat(), 
                metrics=accuracy)
learn.fit_one_cycle(1, 3e-3)
```



<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>




<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>1.437756</td>
      <td>1.175479</td>
      <td>0.622479</td>
      <td>24:36</td>
    </tr>
  </tbody>
</table>



```python
# 그 다음 큰 이미지

learn.dls = get_dls(64, 224)
learn.fine_tune(1, 1e-3)
```



<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>




<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>1.175591</td>
      <td>1.998556</td>
      <td>0.468260</td>
      <td>1:18:21</td>
    </tr>
  </tbody>
</table>




<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>




<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.887408</td>
      <td>0.807292</td>
      <td>0.744959</td>
      <td>1:16:20</td>
    </tr>
  </tbody>
</table>


- 점점 큰 이미지로 학습시키는 것 여러 번 가능
- pre-trained 사용 시 기존 학습 데이터가 내 데이터와 너무 잘 맞아서 weight가 변경될 필요 없을 땐 progressive 사용하면 더 나빠짐

### Test Time Augmentation

    - test set의 center만 aquare로 잘라서 사용
    - 사용하면 안되는 경우 존재: multi label classification 같은 것은 주변에 중요한 정보가 있을 수 있음 (e.g. breed classify -> 주변부에 있는 코의 색깔 등)
    - 해결 1) 자르지 않고 square로 끼워 맞추기
    - 해결 2) 단순히 중간을 자르는 것이 아니라, 잘라낼 부분의 수를 설정해주기 (모델에 수 던져서 예측 가장 잘 되는 수로 선택), 그 후 한 이미지에 대한 여러 변형 만들기 ->TTA

- TTA: 잘라낼 부분의 수를 설정해주기 (모델에 수 던져서 예측 가장 잘 되는 수로 선택) 그 후 한 이미지에 대한 여러 변형 선택된 개수만큼 만들고 각 이미지 당 변형 예측값의 max의 평균 채택
- 모델 트레인에 걸리는 시간은 그대로지만 val set에 적용시켜보는 시간이 증가함
- fastai는 기본적으로 center crop + 여러 개 잘라내서 만드는 방법 사용


```python
# 아까 learn한 모델에 tta 붙여서 다시

preds,targs = learn.tta()
accuracy(preds, targs).item()
```



<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>





<div>
  <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>

</div>






<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>










    0.7505601048469543



### mixup

- 데이터도 적고,, pretrained 쓸 만한 것도 없을 때
    - aug는 dataset에 대한 지식이 있어야 제대로 쓸 수 있음: 증명사진 분류는 aug 안 쓰는게 좋지만 그냥 사진은 쓰는게 좋음, 어떤 경우는 수평 뒤집기가 좋지만 어떤 경우는 수평 수직 둘 다 하는게 좋음 ...
    - 어떤 지점에서 가장 잘 작동하는 지 알기 위해서는 더 변형하고, 덜 변형하는 방법이 필요함: aug는 별로
--------
- 0) one image is piacked
- 1) Select another image from your dataset at random.
- 2) Pick a weight at random.
- 3) Take a weighted average (using the weight from step 2) of the selected image with your image; this will be your independent variable.
- 4) Take a weighted average (with the same weight of 2 and 3) of this image's labels with your image's labels; this will be your dependent variable.
--------
>image2,target2 = dataset[randint(0,len(dataset)] <br/>
t = random_float(0.5,1.0) <br/>
new_image = t * image1 + (1-t) * image2 <br/>
new_target = t * target1 + (1-t) * target2 <br/>

![png](/../../images/fastai_ch7/mixup1.png)<br/>
타겟이 원핫인코딩 되어있어야함


```python
church = PILImage.create(get_image_files_sorted(path/'train'/'n03028079')[0])
gas = PILImage.create(get_image_files_sorted(path/'train'/'n03425413')[0])
church = church.resize((256,256))
gas = gas.resize((256,256))
tchurch = tensor(church).float() / 255.
tgas = tensor(gas).float() / 255.

_,axs = plt.subplots(1, 3, figsize=(12,4))
show_image(tchurch, ax=axs[0]);
show_image(tgas, ax=axs[1]);
show_image((0.3*tchurch + 0.7*tgas), ax=axs[2]);
```



![png](/../../images/fastai_ch7/output_18_0.png)
    


- the model should predict 30% church and 70% gas station
- "church" is represented by the index 2 and "gas station" is represented by the index 7 -> [0, 0, 0.3, 0, 0, 0, 0, 0.7, 0, 0]
--------
 - these are done by fastai callback "Learner"
 - c.f. callbacks(cbs): sth used to inject custom behavior(like a learning rate schedule, or training in mixed precision) in the training loop

>model = xresnet50(n_out=dls.c)<br/>
learn = Learner(dls, model, loss_func=CrossEntropyLossFlat(), <br/>
　　　metrics=accuracy, cbs=MixUp())<br/>
learn.fit_one_cycle(5, 3e-3)<br/>

--------
- it's going to be harder to train (it's harder to see what's in each image)
- less overfitting: 한 에폭에 사용한 이미지는 다시 사용하지 않음 (새로운 조합으로 섞은 이미지 만들어서 다음 에폭에 사용)
- 지금까지의 다른 aug보다 더 많이 돌려야 좋은 성능 나옴
- 사진이 아닌 다른 형태의 data에도 적용 가능, activation에도 mixup 사용 가능 (NPL등에도 사용 가능)
- target 0, 1이이면 epoch을 거듭할수록 activation이 extreme해짐 (0, 1 = act func 그래프에서 닿을 수 없는 값), but mixup은 0, 1이 아니라서 해결 가능
- can "accidentally" make the labels bigger than 0, or smaller than 1: 01에서 멀게 할건지 가깝게 할건지 설정 가능 -> label smoothing

### Label Smoothing

- loss on class problems: targets are 0ne hor encodded 문제점: 하나는 1로 나머지는 다 0으로 return 하도록 train
    - even 0.999 is not "good enough", the model will get gradients and learn to predict activations with even higher confidence -> overfit
    - 반대로 it will always say 1 for the predicted category even if it's not too sure, just because it was trained this way -> overfit
- 1) data가 완벽하게labeled되지 않은 상황에서는 위험!
- 2) overfit 될 수 있음(작은 변화도 민감하게 받아들임, 닿을 수 없는 0, 1에 근접하려고 하니 extreme 해짐)
- 해결) label smoothing으로 1보다 좀 작고, 0보다 좀 큰 라벨로 대체 가능 -> make model less confident -> 잘못 라벨링 된 데이터 있어도 좀 나아, 적용 better
-------
- 1) one hot encodded label (실제로는 아니지만 예시를 들자면)
- 2) replace all 0s with (epsilon: 0.1)/N(the number of classes) = 0에 대해 10% 불확실함
- 3) replace the 1 by 1 - (epsilon) +(epsilon)/N = 다 더해서 1 되도록
-------
>model = xresnet50(n_out=dls.c)<br/>
learn = Learner(dls, model, loss_func=LabelSmoothingCrossEntropy(), <br/>
　　　　　　　metrics=accuracy)<br/>
learn.fit_one_cycle(5, 3e-3)
---------
- mixup처럼 많은 에폭 돌려야 효과적
