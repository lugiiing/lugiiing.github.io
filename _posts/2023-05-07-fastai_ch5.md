---
layout: post
title: "fastai_ch5"
---



```python
#hide
! pip install -Uqq fastbook
import fastbook
fastbook.setup_book()
```


```python
#hide
from fastbook import *
```


```python
from fastai.vision.all import *
path = untar_data(URLs.PETS)
```

## 파일명에서 정보 추출하기


```python
#hide
Path.BASE_PATH = path
```


```python
path.ls()
```




    (#2) [Path('annotations'),Path('images')]




```python
(path/"images").ls()
```




    (#7393) [Path('images/Abyssinian_1.jpg'),Path('images/Abyssinian_10.jpg'),Path('images/Abyssinian_100.jpg'),Path('images/Abyssinian_100.mat'),Path('images/Abyssinian_101.jpg'),Path('images/Abyssinian_101.mat'),Path('images/Abyssinian_102.jpg'),Path('images/Abyssinian_102.mat'),Path('images/Abyssinian_103.jpg'),Path('images/Abyssinian_104.jpg')...]



테스트


```python
fname = (path/"images").ls()[0]
```

### regex (regular expression)

- deciding if another string passes a test (i.e., "matches" the regular expression)
- possibly for plucking a particular part or parts out of that other string
- 특정한 규칙을 가진 문자열의 집합을 표현하는 데 사용하는 형식 언어
- 특정한 조건의 문자를 검색, 치환 하는 것 간편하게
- 표현 방법 숙지해야 함 (메타문자)

![png](/../../images/fastai_ch5/regex1.png)

![png](/../../images/fastai_ch5/regex2.png)

![png](/../../images/fastai_ch5/regex3.png)

![png](/../../images/fastai_ch5/regex4.png)

- https://learn.microsoft.com/en-us/dotnet/standard/base-types/regular-expression-language-quick-reference


```python
re.findall(r'(.+)_\d+.jpg$', fname.name)

# 으잉 책이랑 다르네,, 고양이라고 합니다
```




    ['Abyssinian']



### labeling_RegexLabeller
### Datablock


```python
# block API
# = when you don't have an application and data structure 
# that happen to fit into those predefined methods (things required for some tools)
# can fully customize every stage of the creation of your tool(DataLoaders)

pets = DataBlock(blocks = (ImageBlock, CategoryBlock),
                 get_items=get_image_files, 
                 splitter=RandomSplitter(seed=42),
                 get_y=using_attr(RegexLabeller(r'(.+)_\d+.jpg$'), 'name'),
                 item_tfms=Resize(460),                                # presizing
                 batch_tfms=aug_transforms(size=112, min_scale=0.75))  # presizing
dls = pets.dataloaders(path/"images")
```

- we have to.. (about presizing)
    - make images to have same dimensions (crop, pad, squish)
    - minimize the number of distinct augmentation computations we perform (! 한번에 자동으로 이미지 증강 한다는 뜻인가?)
    - if augmentation -> resize (x, spurious empty zones, degraded data)
    - thus, resize(item_tfms, larger than target's dimensions) -> augmentation(batch_tfms)


```python
#hide_input
#id interpolations
#caption A comparison of fastai's data augmentation strategy (left) and the traditional approach (right).
dblock1 = DataBlock(blocks=(ImageBlock(), CategoryBlock()),
                   get_y=parent_label,
                   item_tfms=Resize(460))
# Place an image in the 'images/grizzly.jpg' subfolder where this notebook is located before running this
dls1 = dblock1.dataloaders([(Path.cwd()/'images'/'grizzly.jpg')]*100, bs=8)
dls1.train.get_idxs = lambda: Inf.ones
x,y = dls1.valid.one_batch()
_,axs = subplots(1, 2)

x1 = TensorImage(x.clone())
x1 = x1.affine_coord(sz=224)
x1 = x1.rotate(draw=30, p=1.)
x1 = x1.zoom(draw=1.2, p=1.)
x1 = x1.warp(draw_x=-0.2, draw_y=0.2, p=1.)

tfms = setup_aug_tfms([Rotate(draw=30, p=1, size=224), Zoom(draw=1.2, p=1., size=224),
                       Warp(draw_x=-0.2, draw_y=0.2, p=1., size=224)])  # ! 사이즈를 더 크게 잡지 않았는데 어떻게 화질이 좋지..?

# ! wrap: interpolate?
# ! affine: interpolate?

x = Pipeline(tfms)(x)
#x.affine_coord(coord_tfm=coord_tfm, sz=size, mode=mode, pad_mode=pad_mode)
TensorImage(x[0]).show(ctx=axs[0])
TensorImage(x1[0]).show(ctx=axs[1]);
```


    
![png](/../../images/fastai_ch5/output_14_0.png)
    


## 데이터 확인하기(데이터 디버깅)

### datablock for debugging 
- not the code error, but about the downgraded images
- check that each one seems to have the correct label for that breed of pet
- use summary mthd
- check any missing codes (e.g. resize)


```python
dls.show_batch(nrows=1, ncols=3)
```


    
![png](/../../images/fastai_ch5/output_16_0.png)
    


## 간단한 모델 트레이닝

- 데이터가 대단한 pretrainned model 없이도 좋은 모델을 뽑아낼 수도 있다
- 데이터로 아무리 학습시켜도 모델 성능이 안나올 수도 있다


```python
learn = vision_learner(dls, resnet34, metrics=error_rate)
learn.fine_tune(2)

# loss function은 아마 자동으로 cross entropy (이미지 분류에 적합)
```

    C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\site-packages\torchvision\models\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
      warnings.warn(
    C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\site-packages\torchvision\models\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.
      warnings.warn(msg)
    



<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>




<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>error_rate</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>1.508393</td>
      <td>0.326430</td>
      <td>0.104871</td>
      <td>14:05</td>
    </tr>
  </tbody>
</table>




<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>




<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>error_rate</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.488636</td>
      <td>0.328622</td>
      <td>0.106225</td>
      <td>16:46</td>
    </tr>
    <tr>
      <td>1</td>
      <td>0.305019</td>
      <td>0.210632</td>
      <td>0.066982</td>
      <td>15:55</td>
    </tr>
  </tbody>
</table>


### Cross-Entropy Loss

- loss function
- 2개 이상의 분류범주에도 작동
- fast
- reliable
- actual data, activations(function) -> loss function

### actual data


```python
x,y = dls.one_batch()  
# one batch of real data from dls
```


```python
y
# 총 37개의 범주
```




    TensorCategory([14,  3, 18, 34, 36, 22,  9,  2,  8, 11, 23,  2, 23, 22,  8,  6, 15, 26, 35, 16,  9, 30, 13, 11, 14,  1, 18, 17, 23,  6, 28, 24, 17, 29, 31,  5, 26,  6, 36,  2, 25, 25, 11, 16,  5, 29,
                    35, 20, 32, 12, 36,  8, 36,  0,  6, 15, 30, 27, 19,  9,  4, 32, 23,  4])




```python
preds,_ = learn.get_preds(dl=[(x,y)])
# 한 개의 배치로 예측한 것 (타깃 제외) 저장
preds[0]
# trainset(= [0], valid = [1])
```



<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>










    tensor([3.8222e-06, 6.0566e-06, 9.8632e-07, 2.1527e-07, 6.7868e-07, 5.8894e-08, 2.4941e-07, 3.2947e-07, 3.3419e-07, 2.2148e-06, 1.0624e-06, 5.5843e-08, 2.8711e-06, 4.4878e-05, 9.8722e-01, 1.2551e-02,
            4.5839e-06, 1.2442e-06, 1.2078e-05, 4.0137e-06, 8.6466e-07, 4.7921e-07, 2.4178e-06, 1.6056e-07, 6.4850e-07, 4.1370e-07, 2.6866e-05, 3.6573e-07, 1.5009e-06, 2.4207e-07, 1.1566e-05, 1.4792e-05,
            4.8336e-06, 3.4581e-05, 2.5958e-05, 3.0981e-06, 1.4150e-05])




```python
len(preds[0]),preds[0].sum()
```




    (37, tensor(1.))



### activation (sigmoid)

- 0과 1 사이의 값 반환
- 마지막 활성함수로 많이 사용
- 2개 이상의 카테고리가 있을 경우 한 카테고리 당 act func 하나씩 필요
- 더해서 1이 되게 만들지 않음
- x데이터가 주어졌을 때 성공확률을 예측하는 로지스틱 회귀분석은 학습데이터를 잘 설명하는 시그모이드 함수의 w와 b를 찾는 문제
- 두 분류 중 누가 더 큰지 알아야 하므로 차를 시그모이드로 반환
    - 음수였으면 0.5이하, 양수였으면 0.5 이상
    - '뒤'보다 '앞'일 확률: (앞-뒤의 예측값)을 시그모이드로 반환
    - '앞'보다 '뒤'일 확: 은 1 - 위의 값 (0~1의 범위, 1이 점근선이고 0.5를 기준으로 대칭이니 {('뒤'-'앞')의 시그모이드}는 [1 - {('앞'-'뒤')의 시그모이드}])

### activation (softmax)
- 2개 이상의 카테고리가 있을 경우 한 카테고리 당 act func 하나씩 필요
- [두 값의 차를 시그모이드 한 값, 1-앞의값] 반환
    - 더해서 1 (여러 개의 카테고리에 대해서도 항상 더해서 1)
    - 항상 0에서 1 사이의 양수 반환
    - 조금이라도 더 큰 값이 있으면 exp때문에 그 차이가 극대화 (더 큰 값이 더욱 1에 가까워짐)
- 하나를 무조건 고르기 때문에, 각각의 데이터에 대해서 분명한 예측을 할 수 있을 때 사용하는 것이 좋음 (차이가 근소하여 카테고리 하나 고르는 것 보다 모르겠다고 대답하는 편이 좋은 경우에는 각각 시그모이드를 사용하는 이진분류를 여러 개를 보는 것이 좋겠다!!)
- sm_acts[idx, targ]을 풀어서 살펴보면
    - sm_acts(두 카테고리에 대한 softmax 값을 저장한 텐서)에 포함된 텐서들의 행 수에 맞게 index(idx) 어레이 만들어주고, 
    - 타겟도 각 행 당 몇 번째 열의 숫자로 고를 지 적어주면 (targ)
    - sm_acts에 있는 각 행에 대해 타겟에 적혀있는 열의 숫자가 선택되어 출력된다(result)
    - 1-result = loss
    - sm_acts에 두 열 이상 넣어도 동작 가능!
- sm_acts[idx, targ]의 음수 버전이 nll_loss (negative log likelihood loss)

### loss

- Likelihood
    - 우도
    - 샘플값이 모집단 확률분포를 얼마나 잘 반영하고 있는가
    - 확률값의 곱들로 표현 
    - (! 그럼 단순히 확률이 높은 값이 많아질수록 우도가 커지는 것 아닌가?))
    - 최대우도: 우도를 최대화하는 지점의 세타(정규본포는 평균과 표준편차)값 찾기
    
- Log Likelihood
    - Likelihood에 로그를 취해서 최대우도를 찾기 위한 곱셈 과정을 덧셈으로 단순화 시킨 모습
    
- negative log likelihood loss(nll_loss)
    - -sm_acts[idx, targ] (로그 때문에 음수 됨)
    - 하지만 pytorch에서 loss function 단계에서는 실제로 로그를 취하지는 않음 (이미 log_softmax라는 함수를 사용했기 때문에, 그 다음에 쓰는 것이라는 의미로 log가 붙었다. )
    - 로그에 대하여,,, 
        - 0부터 1값은 그냥 로그 취하면 -값이 나오므로 numerical underflow 피하기 위해 -log 사용
        - 게다가 loss 니까 좋은 예측(1근접)일때 작은 수 반환하고 나쁜 예측(0근접)일 때 큰 수 반환하니까..
        - 로그 취하면 차이가 더 잘 보이니까..
        - 그리고 덧셈 연산으로 곱셈 효과가 나니까,,
        - 그리고 잘 된 예측이라도 조금의 loss는 발생하는데 그것을 집어내니까.. 성능 개선에 효과적
    - nll은 예측치에 -로그 씌운 값 (df['loss'] = -torch.log(tensor(df['result'])))

### negative log likelihood loss (=cross-entropy loss)


- loglikelihood(softmax) = nll_loss(log_softmax) = nn.CrossEntropyLoss
- softmax의 손실함수
- pytorch loss function: class > function
- loss 평균값 아니고 각 데이터별로 수집: reduction='none'
- 그라디언트(기울기, gradient is proportional to the difference between the prediction and the target) 계산 시 유용: cross_entropy(a,b) = softmax(a)-b

## Model interpretation
 - interpret loss functions directly (built for computers to optimize) -> metric (just for understance)


```python
interp = ClassificationInterpretation.from_learner(learn)
interp.plot_confusion_matrix(figsize=(12,12), dpi=60)

# hard to read ->most_confused(worst 5(or more) predictions)
```



<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>









<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>








    
![png](/../../images/fastai_ch5/output_30_4.png)
    



```python
interp.most_confused(min_val=5)
```



<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>










    [('Egyptian_Mau', 'Bengal', 6),
     ('Ragdoll', 'Birman', 5),
     ('Russian_Blue', 'British_Shorthair', 5)]



## Improving Our Model

### how to fine-tune our pretrained model
without breaking the pretrained weights

- The learning rate finder
    - to start with a very, very small learning rate (use that for one mini-batch)
    - increase the learning rate by some percentage (e.g., doubling it each time)
    - until the loss gets worse
    - select a learning rate a bit lower than this point (One order of magnitude less than where the minimum loss was achieved, The last point where the loss was clearly decreasing)


```python
learn = vision_learner(dls, resnet34, metrics=error_rate)
lr_min,lr_steep = learn.lr_find(suggest_funcs=(minimum, steep))
```



<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>








    
![png](/../../images/fastai_ch5/output_35_2.png)
    



```python
print(f"Minimum/10: {lr_min:.2e}, steepest point: {lr_steep:.2e}")
```

    Minimum/10: 8.32e-03, steepest point: 4.37e-03
    


```python
# In this learning rate plot it appears that a learning rate around 3e-3 would be appropriate
# middle point between 1e-3 and 1e-2 is between 3e-3 and 4e-3

learn = vision_learner(dls, resnet34, metrics=error_rate)
learn.fine_tune(2, base_lr=3e-3)
```

    C:\Users\변규리\AppData\Local\Programs\Python\Python311\Lib\site-packages\torchvision\models\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
      warnings.warn(
    C:\Users\변규리\AppData\Local\Programs\Python\Python311\Lib\site-packages\torchvision\models\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.
      warnings.warn(msg)
    



<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>




<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>error_rate</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>2.278009</td>
      <td>0.962894</td>
      <td>0.299729</td>
      <td>19:44</td>
    </tr>
  </tbody>
</table>




<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>




<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>error_rate</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>1.051932</td>
      <td>0.781891</td>
      <td>0.246955</td>
      <td>23:29</td>
    </tr>
    <tr>
      <td>1</td>
      <td>0.697730</td>
      <td>0.517412</td>
      <td>0.158999</td>
      <td>24:00</td>
    </tr>
  </tbody>
</table>


- unfreezing and transfer learning
    - convolutional neural network consists of many linear layers with a nonlinear activation function between each pair, with good weights -> freeze
    - final linear layer is unlikely to be of any use for us when we are fine-tuning in a transfer learning setting, because it is specifically designed to classify the categories in the original pretraining dataset
    - when we do transfer learning, we throw it away, and replace it with a new linear layer with the correct number of outputs for our desired task
    - newly added linear layer will have entirely random weights -> 
    - .fine_tune(): Trains the randomly added layers for one epoch, with all other layers frozen -> Unfreezes all of the layers, and trains them all for the number of epochs requested
    - fit_one_cycle: to start training at a low learning rate, gradually increase it for the first section of training, and then gradually decrease it again for the last section of training


```python
learn = vision_learner(dls, resnet34, metrics=error_rate)
learn.fit_one_cycle(2, 3e-3)
```



<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>




<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>error_rate</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>1.645748</td>
      <td>0.696441</td>
      <td>0.211096</td>
      <td>19:01</td>
    </tr>
    <tr>
      <td>1</td>
      <td>0.903943</td>
      <td>0.540744</td>
      <td>0.167794</td>
      <td>18:24</td>
    </tr>
  </tbody>
</table>



```python
learn.unfreeze()
# ! 왜 녹이는거죠,,,? 다른 레이어 학습시키면 혹시나 더 좋은 loss 있을 수 있어서? ㅇㅇ
```


```python
learn.lr_find()
```



<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>










    SuggestedLRs(valley=6.30957365501672e-05)




    
![png](/../../images/fastai_ch5/output_41_3.png)
    



```python
learn.fit_one_cycle(2, lr_max=1e-5)
# discriminative learning rates
# deepest layers of our pretrained model might not need as high a learning rate as the last ones, 
# so we should probably use different learning rates for those
```



<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>




<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>error_rate</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.694596</td>
      <td>0.504398</td>
      <td>0.156969</td>
      <td>23:59</td>
    </tr>
    <tr>
      <td>1</td>
      <td>0.645167</td>
      <td>0.490567</td>
      <td>0.154939</td>
      <td>22:51</td>
    </tr>
  </tbody>
</table>


- Discriminative Learning Rates
    - The first layer learns very simple foundations (ch1, edge and gradient detectors) -> likely to be just as useful for nearly any task
    - The later layers learn much more complex concepts (e.g. sunsets) -> might not be useful in your task at all
    - done by slice object (The first value = earliest layer lr, the second value = the lr in the final layer)


```python
learn = vision_learner(dls, resnet34, metrics=error_rate)
learn.fit_one_cycle(2, 3e-3)
learn.unfreeze()
learn.fit_one_cycle(3, lr_max=slice(1e-6,1e-4))
```



<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>




<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>error_rate</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>1.631424</td>
      <td>0.700244</td>
      <td>0.215832</td>
      <td>19:47</td>
    </tr>
    <tr>
      <td>1</td>
      <td>0.929091</td>
      <td>0.519336</td>
      <td>0.163058</td>
      <td>19:16</td>
    </tr>
  </tbody>
</table>




<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>




<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>error_rate</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.689449</td>
      <td>0.493493</td>
      <td>0.161028</td>
      <td>24:52</td>
    </tr>
    <tr>
      <td>1</td>
      <td>0.646693</td>
      <td>0.470759</td>
      <td>0.156969</td>
      <td>23:36</td>
    </tr>
    <tr>
      <td>2</td>
      <td>0.599808</td>
      <td>0.469434</td>
      <td>0.149526</td>
      <td>22:46</td>
    </tr>
  </tbody>
</table>



```python
learn.recorder.plot_loss()
```


    
![png](/../../images/fastai_ch5/output_45_0.png)
    


accuracy continues improving, even as the validation loss gets worse

-> in the end what matters is your accuracy, or more generally your chosen metrics, not the loss

- Selecting the Number of Epochs
    -  early stopping: this is very unlikely to give you the best answer
    - because those epochs in the middle occur before the learning rate has had a chance to reach the small values
    - ->if you find that you have overfit, what you should actually do is retrain your model from scratch, select a total number of epochs based on where your previous best results were found
    - If you have the time to train for more epochs, you may want to instead use that time to train more parameters—that is, use a deeper architecture.

- Deeper Architectures
    - In general, a model with more parameters can model your data more accurately.
    - -> we should choose a number of layers that have already been pretrained for us
    - larger version (e.g. ResNet 18, 34, 50, 101, and "152") -> suffer more from overfitting (because it has more parameters to overfit with)
    - and to avoid OOM error, lower the size of batches
    - mixed-precision training: solve long training time caused by deeper layers (using less-precise numbers, fp16) -> to_fp16() (after your Learner creation)


```python
from fastai.callback.fp16 import *
learn = vision_learner(dls, resnet50, metrics=error_rate).to_fp16()
learn.fine_tune(3, freeze_epochs=3)
```

    C:\Users\변규리\AppData\Local\Programs\Python\Python311\Lib\site-packages\torchvision\models\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.
      warnings.warn(msg)
    Downloading: "https://download.pytorch.org/models/resnet50-0676ba61.pth" to C:\Users\변규리/.cache\torch\hub\checkpoints\resnet50-0676ba61.pth
    100%|█████████████████████████████████████████████████████████████████████████████| 97.8M/97.8M [00:08<00:00, 11.5MB/s]
    C:\Users\변규리\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\amp\autocast_mode.py:204: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling
      warnings.warn('User provided device_type of \'cuda\', but CUDA is not available. Disabling')
    C:\Users\변규리\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\cuda\amp\grad_scaler.py:120: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.
      warnings.warn("torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.")
    



<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>




<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>error_rate</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>2.184511</td>
      <td>0.921876</td>
      <td>0.281461</td>
      <td>32:15</td>
    </tr>
    <tr>
      <td>1</td>
      <td>1.301076</td>
      <td>0.726035</td>
      <td>0.221245</td>
      <td>28:49</td>
    </tr>
    <tr>
      <td>2</td>
      <td>0.956282</td>
      <td>0.620772</td>
      <td>0.192828</td>
      <td>30:24</td>
    </tr>
  </tbody>
</table>




<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>




<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>error_rate</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.698798</td>
      <td>0.606188</td>
      <td>0.185386</td>
      <td>34:25</td>
    </tr>
    <tr>
      <td>1</td>
      <td>0.524419</td>
      <td>0.472737</td>
      <td>0.142084</td>
      <td>40:11</td>
    </tr>
    <tr>
      <td>2</td>
      <td>0.311647</td>
      <td>0.415540</td>
      <td>0.127199</td>
      <td>39:07</td>
    </tr>
  </tbody>
</table>

